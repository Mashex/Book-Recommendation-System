{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender_Model():\n",
    "\tdef __init__(self):\n",
    "\t\tself.dataset = pd.read_csv('../scripts/goodbooks-10k-master/ratings.csv')\n",
    "\t\tself.book_data = np.array(list(set(self.dataset.book_id)))\n",
    "\t\tself.books = pd.read_csv('../scripts/goodbooks-10k-master/books.csv')\n",
    "\t\t\n",
    "\tdef create_net(self):\n",
    "\n",
    "\t\ttrain, test = train_test_split(self.dataset, test_size=0.2, random_state=42)\n",
    "\t\tn_users = len(self.dataset.user_id.unique())\n",
    "\t\tn_books = len(self.dataset.book_id.unique())\n",
    "\n",
    "\t\tbook_input = Input(shape=[1], name=\"Book-Input\")\n",
    "\t\tbook_embedding = Embedding(n_books+1, 5, name=\"Book-Embedding\")(book_input)\n",
    "\t\tbook_vec = Flatten(name=\"Flatten-Books\")(book_embedding)\n",
    "\n",
    "\t\tuser_input = Input(shape=[1], name=\"User-Input\")\n",
    "\t\tuser_embedding = Embedding(n_users+1, 5, name=\"User-Embedding\")(user_input)\n",
    "\t\tuser_vec = Flatten(name=\"Flatten-Users\")(user_embedding)\n",
    "\n",
    "\t\tprod = Dot(name=\"Dot-Product\", axes=1)([book_vec, user_vec])\n",
    "\t\t\n",
    "\t\tself.model = Model([user_input, book_input], prod)\n",
    "\t\tself.model.compile('adam', 'mean_squared_error')\n",
    "\n",
    "\t\thistory = self.model.fit([train.user_id, train.book_id], train.rating, epochs=5, verbose=1)\n",
    "\tdef train(self):\n",
    "\t\t# serialize model to JSON\n",
    "\t\tmodel_json = self.model.to_json()\n",
    "\t\twith open(\"model.json\", \"w\") as json_file:\n",
    "\t\t    json_file.write(model_json)\n",
    "\t\t# serialize weights to HDF5\n",
    "\t\tself.model.save_weights(\"model.h5\")\n",
    "\t\tprint(\"Saved model to disk\")\n",
    "\n",
    "\tdef predict(self,user_data = np.array([1 for i in range(len(self.book_data))])):\n",
    "\n",
    "\t\tjson_file = open('model.json', 'r')\n",
    "\t\tloaded_model_json = json_file.read()\n",
    "\t\tjson_file.close()\n",
    "\t\tloaded_model = model_from_json(loaded_model_json)\n",
    "\t\t# load weights into new model\n",
    "\t\tloaded_model.load_weights(\"model.h5\")\n",
    "\t\tprint(\"Loaded model from disk\")\n",
    "\n",
    "\t\tloaded_model.compile('adam', 'mean_squared_error')\n",
    "\n",
    "\t\t# Creating dataset for making recommendations for the first user\n",
    "\t\tif len(user_data) != len(self.book_data):\n",
    "\t\t\treturn\n",
    "\t\tuser = np.array([1 for i in range(len(self.book_data))])\n",
    "\t\t#user = np.array(user_data) #[1,1,0,1,0,0,0......0,1,1]\n",
    "\t\tpredictions = loaded_model.predict([user, self.book_data])\n",
    "\t\tpredictions = np.array([a[0] for a in predictions])\n",
    "\t\trecommended_book_ids = (-predictions).argsort()[:5]\n",
    "\n",
    "\t\treturn self.books[self.books['id'].isin(recommended_book_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Recommender_Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4781183/4781183 [==============================] - 409s 86us/step - loss: 4.0663\n",
      "Epoch 2/5\n",
      "4781183/4781183 [==============================] - 405s 85us/step - loss: 0.7941\n",
      "Epoch 3/5\n",
      "4781183/4781183 [==============================] - 416s 87us/step - loss: 0.7716\n",
      "Epoch 4/5\n",
      "4781183/4781183 [==============================] - 396s 83us/step - loss: 0.7553\n",
      "Epoch 5/5\n",
      "4781183/4781183 [==============================] - 395s 83us/step - loss: 0.7413\n"
     ]
    }
   ],
   "source": [
    "mod.create_net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "mod.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'user_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-eef8d665c1c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'user_data'"
     ]
    }
   ],
   "source": [
    "mod.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
